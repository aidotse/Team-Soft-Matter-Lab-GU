{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1A - Virtual staining of brightfield images (60x)\n",
    "\n",
    "Example code to virtually staining brightfield images captured with the 60x magnification objective obtaining the corresponding images for nuclei, lipids and cytoplasm.\n",
    "\n",
    "This example can be used to virtually stain other brightfield images by changing the loading and saving user-defined in section 1.1. below.\n",
    "\n",
    "version 1.0 <br />\n",
    "15 November 2020 <br />\n",
    "Benjamin Midtvedt, Jes√∫s Pineda Castro, Saga Helgadottir, Daniel Midtvedt & Giovanni Volpe <br />\n",
    "Soft Matter Lab @ GU <br />\n",
    "http://www.softmatterlab.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    " \n",
    "Import all necessary packages. These include standard Python packages as well as the core of DeepTrack 2.0 (`deeptrack`) and some specialized classes for this virtual staining (`apido`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deeptrack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e47483857e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# DeepTrack 2.0 code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdeeptrack\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deeptrack'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# DeepTrack 2.0 code\n",
    "import deeptrack as dt\n",
    "import apido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define input and output\n",
    "\n",
    "Set constants to determine the input and output images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 User-defined constants to load test images and save the virtually stained images\n",
    "\n",
    "Constants defined by the user:\n",
    "\n",
    "* `DATASET_PATH`: Input path (not including the magnification folder)\n",
    "\n",
    "* `OUTPUT_PATH`: Output path (not including the magnication folder)\n",
    "\n",
    "* `WELLS`: Name of the wells on which to predict\n",
    "\n",
    "* `SITES`: \"all\" or list of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./test_data/\" \n",
    "OUTPUT_PATH = \"./test_results/\"\n",
    "WELLS = [\"C02\"]\n",
    "SITES = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inferred constants\n",
    "\n",
    "Constants automatically inferred from the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGNIFICATION = \"60x\"\n",
    "file_name_struct = \"AssayPlate_Greiner_#655090_{0}_T0001F{1}L01A0{2}Z0{3}C0{2}.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer full path to input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_glob_struct = os.path.join(DATASET_PATH, MAGNIFICATION + \"*/\")\n",
    "_glob_results = glob.glob(_glob_struct)\n",
    "\n",
    "if len(_glob_results) == 0:\n",
    "    raise ValueError(\"No path found matching glob {0}\".format(_glob_struct))\n",
    "elif len(_glob_results) > 1:\n",
    "    from warnings import warn\n",
    "    warn(\"Multiple paths found! Using {0}\".format(_glob_results[0]))\n",
    "\n",
    "PATH_TO_MAGNIFICATION = os.path.normpath(_glob_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer path to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: \t ./local_data\\60x images\\\n",
      "Saving results to: \t ./local_data\\60x images\\\n",
      "Grabbing model from: \t D:\\Team-Soft-Matter-Lab-GU\\models\\60x\n"
     ]
    }
   ],
   "source": [
    "_folder_ending = os.path.split(PATH_TO_MAGNIFICATION)[-1]\n",
    "PATH_TO_OUTPUT = os.path.normpatht(\n",
    "    os.path.join(OUTPUT_PATH, _folder_ending)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer path to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = os.path.normpath(\n",
    "    os.path.abspath(\n",
    "        os.path.join(\"..\", \"models\", MAGNIFICATION)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: \t ./local_data\\60x images\\\n",
      "Saving results to: \t ./local_results/./local_data\\60x images\\\n",
      "Grabbing model from: \t D:\\Team-Soft-Matter-Lab-GU\\models\\60x\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading images from: \\t\", PATH_TO_MAGNIFICATION)\n",
    "print(\"Saving results to: \\t\", PATH_TO_OUTPUT)\n",
    "print(\"Loading pretrained model from: \\t\", PATH_TO_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model\n",
    "\n",
    "Load the pretrained virtual stainer from the local path.\n",
    "\n",
    "Note that we expect here some warnings about overwriting `groups`, which are not a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1045: UserWarning: bmidt is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, None, 7 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 2048        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization (Instanc (None, None, None, 3 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         multiple             0           instance_normalization[0][0]     \n",
      "                                                                 instance_normalization_1[0][0]   \n",
      "                                                                 instance_normalization_2[0][0]   \n",
      "                                                                 instance_normalization_3[0][0]   \n",
      "                                                                 instance_normalization_4[0][0]   \n",
      "                                                                 instance_normalization_5[0][0]   \n",
      "                                                                 instance_normalization_6[0][0]   \n",
      "                                                                 instance_normalization_7[0][0]   \n",
      "                                                                 instance_normalization_8[0][0]   \n",
      "                                                                 instance_normalization_9[0][0]   \n",
      "                                                                 instance_normalization_10[0][0]  \n",
      "                                                                 instance_normalization_11[0][0]  \n",
      "                                                                 instance_normalization_12[0][0]  \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 instance_normalization_14[0][0]  \n",
      "                                                                 instance_normalization_15[0][0]  \n",
      "                                                                 instance_normalization_16[0][0]  \n",
      "                                                                 instance_normalization_17[0][0]  \n",
      "                                                                 instance_normalization_18[0][0]  \n",
      "                                                                 instance_normalization_19[0][0]  \n",
      "                                                                 instance_normalization_20[0][0]  \n",
      "                                                                 instance_normalization_21[0][0]  \n",
      "                                                                 instance_normalization_22[0][0]  \n",
      "                                                                 instance_normalization_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 9248        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_1 (Insta (None, None, None, 3 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9248        leaky_re_lu[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_2 (Insta (None, None, None, 3 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18496       leaky_re_lu[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_3 (Insta (None, None, None, 6 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 6 36928       leaky_re_lu[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_4 (Insta (None, None, None, 6 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 6 36928       leaky_re_lu[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_5 (Insta (None, None, None, 6 128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 73856       leaky_re_lu[5][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_6 (Insta (None, None, None, 1 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 1 147584      leaky_re_lu[6][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_7 (Insta (None, None, None, 1 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 1 147584      leaky_re_lu[7][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_8 (Insta (None, None, None, 1 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 2 295168      leaky_re_lu[8][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_9 (Insta (None, None, None, 2 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 590080      leaky_re_lu[9][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, None, None, 2 512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 2 590080      leaky_re_lu[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, None, None, 2 512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 5 1180160     leaky_re_lu[11][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, None, None, 5 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 5 2359808     leaky_re_lu[12][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 5 131584      leaky_re_lu[11][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, None, None, 5 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 5 0           conv2d_12[0][0]                  \n",
      "                                                                 instance_normalization_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, None, None, 5 0           leaky_re_lu[13][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 7 0           up_sampling2d[0][0]              \n",
      "                                                                 leaky_re_lu[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 2 1769728     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, None, None, 2 512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 2 590080      leaky_re_lu[14][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, None, None, 2 512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu[15][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 3 0           up_sampling2d_1[0][0]            \n",
      "                                                                 leaky_re_lu[7][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 1 442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, None, None, 1 256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 1 147584      leaky_re_lu[16][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, None, None, 1 256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu[17][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 1 0           up_sampling2d_2[0][0]            \n",
      "                                                                 leaky_re_lu[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, None, None, 6 128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 36928       leaky_re_lu[18][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, None, None, 6 128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, None, None, 6 0           leaky_re_lu[19][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 9 0           up_sampling2d_3[0][0]            \n",
      "                                                                 leaky_re_lu[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 3 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_20 (Inst (None, None, None, 3 64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 3 9248        leaky_re_lu[20][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_21 (Inst (None, None, None, 3 64          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 9248        leaky_re_lu[21][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_22 (Inst (None, None, None, 3 64          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 1 4624        leaky_re_lu[22][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_23 (Inst (None, None, None, 1 32          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 3 51          leaky_re_lu[23][0]               \n",
      "__________________________________________________________________________________________________\n",
      "scale_layer (ScaleLayer)        (None, None, None, 3 6           conv2d_29[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,784,073\n",
      "Trainable params: 8,784,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "virtual_stainer = apido.load_model(PATH_TO_MODEL)\n",
    "virtual_stainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load input data\n",
    "\n",
    "We define a data pipeline to load brightfield images from storage. This uses DeepTrack 2.0, and follows the structure:\n",
    "\n",
    "1. Load each z-slice of a well-site combination and concatenate them.\n",
    "2. Pad the volume such that the first two dimensions are multiples of 32 (required by the model).\n",
    "3. Correct for misalignment of the fluorescence channel and the brightfield channel (by a pre-calculated parametrization of the offset as a function of magnification and the site)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Find all wells and sites\n",
    "\n",
    "We create an iterator over each well and site. `Itertools.product` produces an iterator over each combination of its input. In this case, each site in each well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_and_sites = list(\n",
    "    itertools.product(\n",
    "        WELLS,\n",
    "        SITES if isinstance(SITES, list) else range(1, 13) \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The root feature\n",
    "\n",
    "We use DeepTrack 2.0 to define the data loader pipeline. The pipeline is a sequence of `features`, which perform computations, controlled by `properties`, which are defined when creating the features. (Note that we any property with any name and value to a feature; if a property is not used by the feature, we refer to it as a dummy property.)\n",
    "\n",
    "The feature `root` is a `DummyFeature`, which is just a container of dummy properties and does not perform any computations.\n",
    "It takes the following arguments:\n",
    "\n",
    "* `well_site_tuple` is a dummy property that cycles through the well-site combinations in `wells_and_sites`\n",
    "* `well` is a dummy property that extracts the well from the `well_site_tuple`\n",
    "* `site` is a dummy property that extracts the site from the `well_site_tuple`\n",
    "\n",
    "Note that `well` and `site` are functions that take `well_site_tuple` as argument. These are dependent properties, and DeepTrack 2.0 will automatically ensure that they receive the correct input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a tuple of form (well, site), and returns the well\n",
    "def get_well_from_tuple(well_site_tuple):\n",
    "    return well_site_tuple[0]\n",
    "\n",
    "# Accepts a tuple of form (well, site), and returns the site as \n",
    "# a string formated to be of length 3.\n",
    "def get_site_from_tuple(well_site_tuple):\n",
    "    site_string = \"00\" + str(well_site_tuple[1])\n",
    "    return site_string[-3:]\n",
    "\n",
    "\n",
    "root = dt.DummyFeature(\n",
    "    well_site_tuple=itertools.cycle(wells_and_sites), # On each update, root will grab the next value from this iterator\n",
    "    well=get_well_from_tuple,                         # Grabs the well from the well_site_tuple\n",
    "    site=get_site_from_tuple,                         # Grabs and formats the site from the well_site_tuple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The brightfield image loader\n",
    "\n",
    "We use `deeptrack.LoadImage` to load and concatenate a brightfield stack. It takes the following arguments:\n",
    "\n",
    "* `**root.properties` means that we take the properties of `root` (of importance `well` and `site`). The other properties of LoadImage will now depend on these.\n",
    "* `file_names` is a dummy property, which takes the current well and site as input, and creates a list of file names that we want to load.\n",
    "* `path` is a property used by `LoadImage` to determine which files to load. We calculate it by taking `file_names` as input and returning a list of paths using `os.path.join`.\n",
    "\n",
    "Since `path` is a list, `LoadImage` stacks the images along the last dimension, creating a shaped volume with dimensions (width, height, 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightfield_loader = dt.LoadImage(\n",
    "    **root.properties,\n",
    "    file_names=lambda well, site: [file_name_struct.format(well, site, 4, z) for z in range(1, 8)],\n",
    "    path=lambda file_names: [os.path.join(PATH_TO_MAGNIFICATION, file_name) for file_name in file_names],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Padding\n",
    "\n",
    "The model requires the two primary dimensions of the input to be multiples of 32. We ensure this using `deeptrack.PadToMultiplesOf`. This feature also adds a property which allows us to restore the model prediction to the original shape. It takes the following argument:\n",
    "\n",
    "* `multiple` is a tuple of multiples per dimension. In our case, we set the first two dimentsions to 32 and the third dimension to `None` (meaning that we do not want to pad it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_padded = dt.PadToMultiplesOf(multiple=(32, 32, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Offset adjustment\n",
    "\n",
    "Offset adjustments using affine transformations. The offset is parametrized as a function of the magnification and the site as described in the report.\n",
    "\n",
    "The properties are set as follows:\n",
    "* `translate` sets how much we translate the image in pixels. It is a tuple representing the (x, y) shift. We calculate it as a function of the angular position of the site within the well, with site 1 at angle 0.\n",
    "* `angle` is a dummy property that calculates the angle of the site in radians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation parameters (precalculate, see report)\n",
    "Ax = +2.3054\n",
    "Bx = -0.0315\n",
    "Ay = -0.1352\n",
    "By = -2.3049\n",
    "x =  -0.8363\n",
    "y =  +0.8081\n",
    "scale= 0.99975\n",
    "\n",
    "correct_offset = dt.Affine(\n",
    "    translate=lambda angle: (\n",
    "        (np.cos(angle) * Bx + np.sin(angle) * Ax + x) * -1, # Offset in x\n",
    "        (np.cos(angle) * By + np.sin(angle) * Ay + y) * -1, # Offset in y\n",
    "    ),\n",
    "    angle = lambda site: (int(site) - 1) * np.pi / 6,\n",
    "    **root.properties,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Creating the pipeline \n",
    "\n",
    "We use the `+` operator to chain the features, defining the execution order. In DeepTrack 2.0, this means that the output of the feature on the left is passed as the input to the feature on the right. In other words, the stack loaded by `brightfield_loader` is passed to `ensure_padded`, the output of which is offset-corrected by `correct_offset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightfield_stack_pipeline = brightfield_loader + ensure_padded + correct_offset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate the virtually stained images from the brightfield images\n",
    "\n",
    "In order to have the actual brightfield images needed for further processing, we need to resolve the pipeline `brightfield_stack_pipeline`.\n",
    "\n",
    "Each time we call `update()`, we update each property of all the features in the pipeline, ensuring that each dependent property is updated in the right order. Therefore, at each update, we select a new well-site combination, from which we obtain all other properties (the path of the images, the angle of the site, etc.).\n",
    "\n",
    "The subsequent call to `resolve()` executes each feature in the pipeline in order, producing a brightfield stack.\n",
    "\n",
    "We do this once per image we want to load, for a total number of images set in `num_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4 files\n"
     ]
    }
   ],
   "source": [
    "num_files = len(wells_and_sites)\n",
    "\n",
    "print(\"Loading {0} files\".format(num_files))\n",
    "list_of_brightfield_images = [\n",
    "    brightfield_stack_pipeline.update().resolve() for _ in range(num_files)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate the virtual staining. All we need to do is to call `virtual_stainer.predict`, no further pre- or post-processing needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made 4 predictions in 13.887231400000005 seconds. 3.471807850000001 seconds per image, not bad!\n"
     ]
    }
   ],
   "source": [
    "model_input = np.array(list_of_brightfield_images)\n",
    "start = timer()\n",
    "stains = virtual_stainer.predict(model_input, batch_size=1)\n",
    "end = timer()\n",
    "print(\n",
    "    \"Made {0} predictions in {1} seconds. {2} seconds per image, not bad!\"\n",
    "    .format(num_files, end-start, (end-start) / num_files)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save results\n",
    "\n",
    "Finally, we iterate over all the virtually stained images and store the results to memory. In DeepTrack 2.0, the properties used to create an image with `resolve()` are stored in a field called `properties`, and can easily be retrieved using the utility method `get_property`. Here, we use this information to extract the well and site of the image, which is needed to correctly name the file. Moreover, some features save additional values. One such case is `undo_padding` which is saved by all padding features. This is a tuple of slices that return an numpy array to its original size before padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F001L01A01Z01C01.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F001L01A02Z01C02.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F001L01A03Z01C03.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F002L01A01Z01C01.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F002L01A02Z01C02.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F002L01A03Z01C03.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F003L01A01Z01C01.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F003L01A02Z01C02.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F003L01A03Z01C03.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F004L01A01Z01C01.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F004L01A02Z01C02.tif\n",
      "Saved image to: ./local_results/./local_data\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F004L01A03Z01C03.tif\n"
     ]
    }
   ],
   "source": [
    "output_format = os.path.join(PATH_TO_OUTPUT, file_name_struct)\n",
    "\n",
    "os.makedirs(PATH_TO_OUTPUT, exist_ok=True)\n",
    "\n",
    "for brightfield, prediction in zip(list_of_brightfield_images, stains):\n",
    "    \n",
    "    well = brightfield.get_property(\"well\")\n",
    "    site = brightfield.get_property(\"site\")\n",
    "    \n",
    "    # Undo the padding required by the model\n",
    "    undo_padding = brightfield.get_property(\"undo_padding\")\n",
    "    prediction = prediction[undo_padding]\n",
    "    \n",
    "    for action in range(3):\n",
    "        file_path = output_format.format(well, site, action + 1, 1)\n",
    "        \n",
    "        prediction_layer = Image.fromarray(prediction[..., action].astype(np.uint16))\n",
    "        prediction_layer.save(file_path)\n",
    "        \n",
    "        print(\"Saved image to:\", file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
