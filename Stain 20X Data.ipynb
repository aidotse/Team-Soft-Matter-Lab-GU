{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3A - Virtual staining of brightfield images (20x)\n",
    "\n",
    "Example code to virtually stain brightfield images captured with the 20x magnification objective obtaining the corresponding images for nuclei, lipids and cytoplasm.\n",
    "\n",
    "This example can be used to virtually stain other brightfield images by changing the loading and saving user-defined in section 1.1. below.\n",
    "\n",
    "version 1.0 <br />\n",
    "15 November 2020 <br />\n",
    "Benjamin Midtvedt, Jes√∫s Pineda Castro, Saga Helgadottir, Daniel Midtvedt & Giovanni Volpe <br />\n",
    "Soft Matter Lab @ GU <br />\n",
    "http://www.softmatterlab.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    " \n",
    "Import all necessary packages. These include standard Python packages as well as the core of DeepTrack 2.0 (`deeptrack`) and some specialized classes for this virtual staining (`apido`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# DeepTrack 2.0 code\n",
    "import apido\n",
    "from apido import deeptrack as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define input and output\n",
    "\n",
    "Set constants to determine the input and output images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 User-defined constants to load test images and save the virtually stained images\n",
    "\n",
    "Constants defined by the user:\n",
    "\n",
    "* `DATASET_PATH`: Input path (not including the magnification folder)\n",
    "\n",
    "* `OUTPUT_PATH`: Output path (not including the magnication folder)\n",
    "\n",
    "* `WELLS`: Name of the wells on which to predict\n",
    "\n",
    "* `SITES`: List of integers with corresponding sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./validation_data/\" \n",
    "OUTPUT_PATH = \"./validation_results/\"\n",
    "WELLS = [\"C02\"]  # [\"B02\"] * 12\n",
    "SITES = [2, 3, 4]  # range(1, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inferred constants\n",
    "\n",
    "Constants automatically inferred from the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGNIFICATION = \"20x\"\n",
    "file_name_struct = \"AssayPlate_Greiner_#655090_{0}_T0001F{1}L01A0{2}Z0{3}C0{2}.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer full path to input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_glob_struct = os.path.join(DATASET_PATH, MAGNIFICATION + \"*/\")\n",
    "_glob_results = glob.glob(_glob_struct)\n",
    "\n",
    "if len(_glob_results) == 0:\n",
    "    raise ValueError(\"No path found matching glob {0}\".format(_glob_struct))\n",
    "elif len(_glob_results) > 1:\n",
    "    from warnings import warn\n",
    "    warn(\"Multiple paths found! Using {0}\".format(_glob_results[0]))\n",
    "\n",
    "PATH_TO_MAGNIFICATION = os.path.normpath(_glob_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer path to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_folder_ending = os.path.split(PATH_TO_MAGNIFICATION)[-1]\n",
    "PATH_TO_OUTPUT = os.path.normpath(\n",
    "    os.path.join(OUTPUT_PATH, _folder_ending)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer path to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = os.path.normpath(\n",
    "    os.path.abspath(\n",
    "        os.path.join(\"models\", MAGNIFICATION)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: \t\t validation_data\\60x images\n",
      "Saving results to: \t\t validation_results\\60x images\n",
      "Loading pretrained model from: \t D:\\Team-Soft-Matter-Lab-GU\\models\\60x\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading images from: \\t\\t\", PATH_TO_MAGNIFICATION)\n",
    "print(\"Saving results to: \\t\\t\", PATH_TO_OUTPUT)\n",
    "print(\"Loading pretrained model from: \\t\", PATH_TO_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model\n",
    "\n",
    "Load the pretrained virtual stainer from the local path.\n",
    "\n",
    "Note that we expect here some warnings about overwriting `groups`, which are not a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1045: UserWarning: bmidt is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, None, 7 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 2048        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization (Instanc (None, None, None, 3 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         multiple             0           instance_normalization[0][0]     \n",
      "                                                                 instance_normalization_1[0][0]   \n",
      "                                                                 instance_normalization_2[0][0]   \n",
      "                                                                 instance_normalization_3[0][0]   \n",
      "                                                                 instance_normalization_4[0][0]   \n",
      "                                                                 instance_normalization_5[0][0]   \n",
      "                                                                 instance_normalization_6[0][0]   \n",
      "                                                                 instance_normalization_7[0][0]   \n",
      "                                                                 instance_normalization_8[0][0]   \n",
      "                                                                 instance_normalization_9[0][0]   \n",
      "                                                                 instance_normalization_10[0][0]  \n",
      "                                                                 instance_normalization_11[0][0]  \n",
      "                                                                 instance_normalization_12[0][0]  \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 instance_normalization_14[0][0]  \n",
      "                                                                 instance_normalization_15[0][0]  \n",
      "                                                                 instance_normalization_16[0][0]  \n",
      "                                                                 instance_normalization_17[0][0]  \n",
      "                                                                 instance_normalization_18[0][0]  \n",
      "                                                                 instance_normalization_19[0][0]  \n",
      "                                                                 instance_normalization_20[0][0]  \n",
      "                                                                 instance_normalization_21[0][0]  \n",
      "                                                                 instance_normalization_22[0][0]  \n",
      "                                                                 instance_normalization_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 9248        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_1 (Insta (None, None, None, 3 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9248        leaky_re_lu[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_2 (Insta (None, None, None, 3 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18496       leaky_re_lu[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_3 (Insta (None, None, None, 6 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 6 36928       leaky_re_lu[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_4 (Insta (None, None, None, 6 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 6 36928       leaky_re_lu[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_5 (Insta (None, None, None, 6 128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 73856       leaky_re_lu[5][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_6 (Insta (None, None, None, 1 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 1 147584      leaky_re_lu[6][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_7 (Insta (None, None, None, 1 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 1 147584      leaky_re_lu[7][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_8 (Insta (None, None, None, 1 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 2 295168      leaky_re_lu[8][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_9 (Insta (None, None, None, 2 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 590080      leaky_re_lu[9][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, None, None, 2 512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 2 590080      leaky_re_lu[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, None, None, 2 512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 5 1180160     leaky_re_lu[11][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, None, None, 5 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 5 2359808     leaky_re_lu[12][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 5 131584      leaky_re_lu[11][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, None, None, 5 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 5 0           conv2d_12[0][0]                  \n",
      "                                                                 instance_normalization_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, None, None, 5 0           leaky_re_lu[13][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 7 0           up_sampling2d[0][0]              \n",
      "                                                                 leaky_re_lu[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 2 1769728     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, None, None, 2 512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 2 590080      leaky_re_lu[14][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, None, None, 2 512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu[15][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 3 0           up_sampling2d_1[0][0]            \n",
      "                                                                 leaky_re_lu[7][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 1 442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, None, None, 1 256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 1 147584      leaky_re_lu[16][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, None, None, 1 256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu[17][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 1 0           up_sampling2d_2[0][0]            \n",
      "                                                                 leaky_re_lu[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, None, None, 6 128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 36928       leaky_re_lu[18][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, None, None, 6 128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, None, None, 6 0           leaky_re_lu[19][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 9 0           up_sampling2d_3[0][0]            \n",
      "                                                                 leaky_re_lu[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 3 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_20 (Inst (None, None, None, 3 64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 3 9248        leaky_re_lu[20][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_21 (Inst (None, None, None, 3 64          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 9248        leaky_re_lu[21][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_22 (Inst (None, None, None, 3 64          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 1 4624        leaky_re_lu[22][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_23 (Inst (None, None, None, 1 32          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 3 51          leaky_re_lu[23][0]               \n",
      "__________________________________________________________________________________________________\n",
      "scale_layer (ScaleLayer)        (None, None, None, 3 6           conv2d_29[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,784,073\n",
      "Trainable params: 8,784,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "virtual_stainer = apido.load_model(PATH_TO_MODEL)\n",
    "virtual_stainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load input data\n",
    "\n",
    "We define a data pipeline to load brightfield images from storage. This uses DeepTrack 2.0, and follows the structure:\n",
    "\n",
    "1. Load each z-slice of a well-site combination and concatenate them.\n",
    "2. Pad the volume such that the first two dimensions are multiples of 32 (required by the model).\n",
    "3. Correct for misalignment of the fluorescence channel and the brightfield channel (by a pre-calculated parametrization of the offset as a function of magnification and the site)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Find all wells and sites\n",
    "\n",
    "We create an list over each well and site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_and_sites = list(zip(WELLS,SITES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The root feature\n",
    "\n",
    "We use DeepTrack 2.0 to define the data loader pipeline. The pipeline is a sequence of `features`, which perform computations, controlled by `properties`, which are defined when creating the features. (Note that we any property with any name and value to a feature; if a property is not used by the feature, we refer to it as a dummy property.)\n",
    "\n",
    "The feature `root` is a `DummyFeature`, which is just a container of dummy properties and does not perform any computations.\n",
    "It takes the following arguments:\n",
    "\n",
    "* `well_site_tuple` is a dummy property that cycles through the well-site combinations in `wells_and_sites`\n",
    "* `well` is a dummy property that extracts the well from the `well_site_tuple`\n",
    "* `site` is a dummy property that extracts the site from the `well_site_tuple`\n",
    "\n",
    "Note that `well` and `site` are functions that take `well_site_tuple` as argument. These are dependent properties, and DeepTrack 2.0 will automatically ensure that they receive the correct input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a tuple of form (well, site), and returns the well\n",
    "def get_well_from_tuple(well_site_tuple):\n",
    "    return well_site_tuple[0]\n",
    "\n",
    "# Accepts a tuple of form (well, site), and returns the site as \n",
    "# a string formated to be of length 3.\n",
    "def get_site_from_tuple(well_site_tuple):\n",
    "    site_string = \"00\" + str(well_site_tuple[1])\n",
    "    return site_string[-3:]\n",
    "\n",
    "\n",
    "root = dt.DummyFeature(\n",
    "    well_site_tuple=itertools.cycle(wells_and_sites), # On each update, root will grab the next value from this iterator\n",
    "    well=get_well_from_tuple,                         # Grabs the well from the well_site_tuple\n",
    "    site=get_site_from_tuple,                         # Grabs and formats the site from the well_site_tuple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The brightfield image loader\n",
    "\n",
    "We use `deeptrack.LoadImage` to load and concatenate a brightfield stack. It takes the following arguments:\n",
    "\n",
    "* `**root.properties` means that we take the properties of `root` (of importance `well` and `site`). The other properties of LoadImage will now depend on these.\n",
    "* `file_names` is a dummy property, which takes the current well and site as input, and creates a list of file names that we want to load.\n",
    "* `path` is a property used by `LoadImage` to determine which files to load. We calculate it by taking `file_names` as input and returning a list of paths using `os.path.join`.\n",
    "\n",
    "Since `path` is a list, `LoadImage` stacks the images along the last dimension, creating a shaped volume with dimensions (width, height, 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightfield_loader = dt.LoadImage(\n",
    "    **root.properties,\n",
    "    file_names=lambda well, site: [file_name_struct.format(well, site, 4, z) for z in range(1, 8)],\n",
    "    path=lambda file_names: [os.path.join(PATH_TO_MAGNIFICATION, file_name) for file_name in file_names],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Padding\n",
    "\n",
    "The model requires the two primary dimensions of the input to be multiples of 32. We ensure this using `deeptrack.PadToMultiplesOf`. This feature also adds a property which allows us to restore the model prediction to the original shape. It takes the following argument:\n",
    "\n",
    "* `multiple` is a tuple of multiples per dimension. In our case, we set the first two dimentsions to 32 and the third dimension to `None` (meaning that we do not want to pad it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_padded = dt.PadToMultiplesOf(multiple=(32, 32, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Offset adjustment\n",
    "\n",
    "Offset adjustments using affine transformations. The offset is parametrized as a function of the magnification and the site as described in the report.\n",
    "\n",
    "The properties are set as follows:\n",
    "* `translate` sets how much we translate the image in pixels. It is a tuple representing the (x, y) shift. We calculate it as a function of the angular position of the site within the well, with site 1 at angle 0.\n",
    "* `scale` sets how much we rescale the image.\n",
    "* `angle` is a dummy property that calculates the angle of the site in radians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation parameters (precalculated, see report)\n",
    "Ax = 3.9549,\n",
    "Bx = 0.06653,\n",
    "x = -1.22169,\n",
    "Ay = -0.1979,\n",
    "By = -4.0921,\n",
    "y = 0.7653,\n",
    "scale = 0.9988,\n",
    "\n",
    "correct_offset = dt.Affine(\n",
    "    translate=lambda angle: (\n",
    "        (np.cos(angle) * Bx + np.sin(angle) * Ax + x) * -1, # Offset in x\n",
    "        (np.cos(angle) * By + np.sin(angle) * Ay + y) * -1, # Offset in y\n",
    "    ),\n",
    "    scale=scale,\n",
    "    angle = lambda site: (int(site) - 1) * np.pi / 6,\n",
    "    **root.properties,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Create the pipeline \n",
    "\n",
    "We use the `+` operator to chain the features, defining the execution order. In DeepTrack 2.0, this means that the output of the feature on the left is passed as the input to the feature on the right. In other words, the stack loaded by `brightfield_loader` is passed to `ensure_padded`, the output of which is offset-corrected by `correct_offset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightfield_stack_pipeline = brightfield_loader + ensure_padded + correct_offset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate the virtually stained images from the brightfield images\n",
    "\n",
    "In order to have the actual brightfield images needed for further processing, we need to resolve the pipeline `brightfield_stack_pipeline`.\n",
    "\n",
    "Each time we call `update()`, we update each property of all the features in the pipeline, ensuring that each dependent property is updated in the right order. Therefore, at each update, we select a new well-site combination, from which we obtain all other properties (the path of the images, the angle of the site, etc.).\n",
    "\n",
    "The subsequent call to `resolve()` executes each feature in the pipeline in order, producing a brightfield stack.\n",
    "\n",
    "We do this once per image we want to load, for a total number of images set in `num_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 files\n"
     ]
    }
   ],
   "source": [
    "num_files = len(wells_and_sites)\n",
    "\n",
    "print(\"Loading {0} files\".format(num_files))\n",
    "list_of_brightfield_images = [\n",
    "    brightfield_stack_pipeline.update().resolve() for _ in range(num_files)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate the virtual staining. All we need to do is to call `virtual_stainer.predict`, no further pre- or post-processing needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d/Conv2D (defined at <ipython-input-16-7c8855344925>:3) ]] [Op:__inference_predict_function_13399]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_1/conv2d/Conv2D:\n functional_1/lambda/Tanh (defined at /workspace/Team-Soft-Matter-Lab-GU/src/bmidt.py:82)\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7c8855344925>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_brightfield_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvirtual_stainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m print(\n",
      "\u001b[1;32mc:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mc:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    844\u001b[0m               *args, **kwds)\n\u001b[0;32m    845\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\bmidt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d/Conv2D (defined at <ipython-input-16-7c8855344925>:3) ]] [Op:__inference_predict_function_13399]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_1/conv2d/Conv2D:\n functional_1/lambda/Tanh (defined at /workspace/Team-Soft-Matter-Lab-GU/src/bmidt.py:82)\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "model_input = np.array(list_of_brightfield_images)\n",
    "start = timer()\n",
    "stains = virtual_stainer.predict(model_input, batch_size=1)\n",
    "end = timer()\n",
    "print(\n",
    "    \"Made {0} predictions in {1} seconds. {2} seconds per image, not bad!\"\n",
    "    .format(num_files, end-start, (end-start) / num_files)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save results\n",
    "\n",
    "Finally, we iterate over all the virtually stained images and store the results to memory. In DeepTrack 2.0, the properties used to create an image with `resolve()` are stored in a field called `properties`, and can easily be retrieved using the utility method `get_property`. Here, we use this information to extract the well and site of the image, which is needed to correctly name the file. Moreover, some features save additional values. One such case is `undo_padding` which is saved by all padding features. This is a tuple of slices that return an numpy array to its original size before padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = os.path.join(PATH_TO_OUTPUT, file_name_struct)\n",
    "\n",
    "os.makedirs(PATH_TO_OUTPUT, exist_ok=True)\n",
    "\n",
    "for brightfield, prediction in zip(list_of_brightfield_images, stains):\n",
    "    \n",
    "    well = brightfield.get_property(\"well\")\n",
    "    site = brightfield.get_property(\"site\")\n",
    "    \n",
    "    # Undo the padding required by the model\n",
    "    undo_padding = brightfield.get_property(\"undo_padding\")\n",
    "    prediction = prediction[undo_padding]\n",
    "    \n",
    "    for action in range(3):\n",
    "        file_path = output_format.format(well, site, action + 1, 1)\n",
    "        \n",
    "        prediction_layer = Image.fromarray(prediction[..., action].astype(np.uint16))\n",
    "        prediction_layer.save(file_path)\n",
    "        \n",
    "        print(\"Saved image to:\", file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
